{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sbi.inference import SNPE\n",
    "from sbi import utils as utils\n",
    "from sbi.analysis import run_sbc, sbc_rank_plot\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, Column\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import tarp\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globular Cluster Data\n",
    "gc_filename = \"/raid/users/heigerm/catalogues/sptab_spspectra_rvtab_gcs.fits\"\n",
    "gc_HDUlist = fits.open(gc_filename)\n",
    "\n",
    "# Globular Cluster parameters from sp pipeline\n",
    "gc_sp_tab = Table(gc_HDUlist['SPTAB'].data)  \n",
    "\n",
    "# Globular Cluster Observed Spectra\n",
    "gc_spectra = Table(gc_HDUlist['SPECTRA_SP'].data)\n",
    "\n",
    "# print the globular clusters in gc_spectra\n",
    "set(gc_spectra['gcname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spectra table for each globular cluster\n",
    "gc_names = [\n",
    "    'NGC_2419', 'NGC_5024_M_53', 'NGC_5053', 'NGC_5272_M_3', 'NGC_5466',\n",
    "    'NGC_5634', 'NGC_5904_M_5', 'NGC_6205_M_13', 'NGC_6218_M_12', 'NGC_6229',\n",
    "    'NGC_6341_M_92', 'NGC_7078_M_15', 'NGC_7089_M_2', 'Pal_14', 'Pal_5'\n",
    "]\n",
    "\n",
    "gc_tables = {name: gc_spectra[gc_spectra['gcname'] == name] for name in gc_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the spectra from the three arms for each globular cluster\n",
    "def process_gc_spectra(gc_table):\n",
    "    processed_spectra = Table()\n",
    "    processed_spectra.add_column(Column(name='combined_flux', dtype='object'))\n",
    "    processed_spectra.add_column(Column(name='combined_wavelength', dtype='object'))\n",
    "\n",
    "    for row in gc_table:\n",
    "        flux_B, wavelength_B = row['flx_B'], row['B_WAVELENGTH']\n",
    "        flux_R, wavelength_R = row['flx_R'], row['R_WAVELENGTH']\n",
    "        flux_Z, wavelength_Z = row['flx_Z'], row['Z_WAVELENGTH']\n",
    "\n",
    "        combined_flux = np.concatenate([flux_B, flux_R, flux_Z])\n",
    "        combined_wavelength = np.concatenate([wavelength_B, wavelength_R, wavelength_Z])\n",
    "\n",
    "        sort_order = np.argsort(combined_wavelength)\n",
    "        combined_flux = combined_flux[sort_order]\n",
    "        combined_wavelength = combined_wavelength[sort_order]\n",
    "\n",
    "        global_median = np.median(combined_flux)\n",
    "        combined_flux -= global_median\n",
    "        IQR = np.percentile(combined_flux, 75) - np.percentile(combined_flux, 25)\n",
    "        combined_flux = combined_flux / IQR\n",
    "\n",
    "        processed_spectra.add_row([combined_flux, combined_wavelength])\n",
    "    \n",
    "    return processed_spectra\n",
    "\n",
    "gc_processed_spectra = {name: process_gc_spectra(table) for name, table in gc_tables.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gc data for testing\n",
    "X_gc = {name: np.array([np.array([float(val) for val in array]) for array in spectra['combined_flux']])\n",
    "        for name, spectra in gc_processed_spectra.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gc['NGC_2419'].shape # only 1 object in this gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "feh_pred_gc = {gc_name: [] for gc_name in X_gc.keys()}\n",
    "feh_var_gc = {gc_name: [] for gc_name in X_gc.keys()}\n",
    "for fold in range(num_folds):\n",
    "    # Load the model for the current fold\n",
    "    class Model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Model, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(13787, 4000),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(4000, 2000),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(2000, 1000),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(1000, 500),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(500, 100),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(100, 50))\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "    # Unif Resampling data\n",
    "    model_pkl_file = f\"SBI_Unif_fold_{fold}.pkl\"\n",
    "    \n",
    "    # Original Training data\n",
    "    # model_pkl_file = f\"SBI_fold_{fold}.pkl\"\n",
    "    with open(model_pkl_file, 'rb') as file:\n",
    "        posterior = pickle.load(file)\n",
    "    \n",
    "    # For each globular cluster, make predictions using the loaded model\n",
    "    for gc_name, gc_data in X_gc.items():\n",
    "        # Initialize lists to store predictions and variances for the current GC\n",
    "        feh_pred_gc[gc_name] = []\n",
    "        feh_var_gc[gc_name] = []\n",
    "    \n",
    "        # Iterate through each observation in the GC data\n",
    "        for observation in gc_data:\n",
    "            # Convert the single observation to a PyTorch tensor and add an extra dimension to match input shape\n",
    "            gc_data_tensor = torch.Tensor(observation).unsqueeze(0)\n",
    "        \n",
    "            # Make predictions for the single observation\n",
    "            samples = posterior.sample((250,), x=gc_data_tensor)  # Adjust the number of samples as needed\n",
    "            fe_h = samples[:, 0]  # Extract [Fe/H] predictions\n",
    "        \n",
    "            # Calculate mean and variance of [Fe/H] predictions for the single observation\n",
    "            feh_pred_gc[gc_name].append(torch.mean(fe_h).item())\n",
    "            feh_var_gc[gc_name].append(torch.var(fe_h).item())\n",
    "\n",
    "# Calculate the overall mean and variance of [Fe/H] predictions for each GC across all folds\n",
    "feh_pred_gc_mean = {gc_name: np.mean(values) for gc_name, values in feh_pred_gc.items()}\n",
    "feh_var_gc_mean = {gc_name: np.mean(values) for gc_name, values in feh_var_gc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feh_pred_gc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feh_var_gc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the mean and variance dictionaries to pandas Series for easy DataFrame construction\n",
    "pred_mean_series = pd.Series(feh_pred_gc_mean, name='Pred Mean')\n",
    "pred_var_series = pd.Series(feh_var_gc_mean, name='Pred Variance')\n",
    "\n",
    "# Convert the true values dictionary to a pandas Series\n",
    "true_values_series = pd.Series(true_values, name='True [Fe/H]')\n",
    "\n",
    "# Construct the summary DataFrame\n",
    "summary_df = pd.concat([pred_mean_series, pred_var_series, true_values_series], axis=1)\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globular Cluster Metallicity Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True [Fe/H] values for each GC\n",
    "true_values = {\n",
    "    'NGC_2419': -2.1, 'NGC_5024_M_53': -1.86, 'NGC_5053': -2.3,\n",
    "    'NGC_5272_M_3': -1.5, 'NGC_5466': -2.2, 'NGC_5634': -1.98,\n",
    "    'NGC_5904_M_5': -1.29, 'NGC_6205_M_13': -1.33, 'NGC_6218_M_12': -1.14,\n",
    "    'NGC_6229': -1.13, 'NGC_6341_M_92': -2.31, 'NGC_7078_M_15': -2.37,\n",
    "    'NGC_7089_M_2': -1.65, 'Pal_14': -1.62, 'Pal_5': -1.41\n",
    "}\n",
    "\n",
    "for gc_name, predictions in feh_pred_gc.items():\n",
    "    # Directly convert predictions to a NumPy array\n",
    "    flat_predictions = np.array(predictions)\n",
    "    \n",
    "    # Ensure there are multiple predictions before calculating the KDE\n",
    "    if flat_predictions.size > 1:\n",
    "        # Calculate the KDE\n",
    "        kde = gaussian_kde(flat_predictions)\n",
    "        \n",
    "        # Define a range over which to evaluate the KDE\n",
    "        x_range = np.linspace(flat_predictions.min(), flat_predictions.max(), 500)\n",
    "        \n",
    "        # Evaluate the KDE over the defined range\n",
    "        kde_values = kde(x_range)\n",
    "        \n",
    "        # Create a new figure for the current GC\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(x_range, kde_values, label=f'KDE {gc_name}')\n",
    "        \n",
    "        # Plot the true [Fe/H] value for the current GC\n",
    "        if gc_name in true_values:\n",
    "            plt.axvline(x=true_values[gc_name], color='r', linestyle='--', label=f'True {gc_name}')\n",
    "        \n",
    "        plt.title(f'KDE of [Fe/H] Predictions for {gc_name}')\n",
    "        plt.xlabel('[Fe/H] Predictions')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Skipping {gc_name} due to insufficient data for KDE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3c0d2cb689c9f3ddfdcc20370a54f5a0d1f4658107fa1312f8e0c21d7f27d67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
