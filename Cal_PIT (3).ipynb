{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd10c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calpit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f31506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tingli/anaconda3/envs/abunnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sbi.inference import SNPE\n",
    "from sbi import utils as utils\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, Column\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cd36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the lower SNR cut from Mairead\n",
    "f1 = \"/raid/users/heigerm/catalogues/sptab_spspectra_rvtab_lowsnr.fits\"\n",
    "HDUlist1 = fits.open(f1)\n",
    "sp_tab1 = Table(HDUlist1['SPTAB'].data) \n",
    "apogee_tab1 = Table(HDUlist1[4].data)\n",
    "spectra1 = Table(HDUlist1['SPECTRA_SP'].data) \n",
    "\n",
    "# load the original 7k (SNR larger than 50)\n",
    "f2 = \"/raid/users/heigerm/catalogues/sp_x_apogee_x_spspectra_rvtab.fits\" \n",
    "# sp data\n",
    "HDUlist2 = fits.open(f2)\n",
    "# DESI\n",
    "sp_tab2 = Table(HDUlist2['SPTAB'].data)   \n",
    "# APOGEE\n",
    "apogee_tab2 = Table(HDUlist2['APOGEEDR17'].data) \n",
    "# DESI SP Spectra\n",
    "spectra2 = Table(HDUlist2['SPECTRA_SP'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdface6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-match\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "apogee_coords = SkyCoord(ra=apogee_tab1['RA']*u.degree, dec=apogee_tab1['DEC']*u.degree)\n",
    "spectra_coords = SkyCoord(ra=spectra1['TARGET_RA']*u.degree, dec=spectra1['TARGET_DEC']*u.degree) \n",
    "\n",
    "# Find the closest match for each entry in spectra1 within a tolerance\n",
    "idx, d2d, _ = spectra_coords.match_to_catalog_sky(apogee_coords)\n",
    "\n",
    "tolerance = 1 * u.arcsec\n",
    "\n",
    "matches_within_tolerance = d2d < tolerance\n",
    "apogee_tab1_matched = apogee_tab1[idx[matches_within_tolerance]]\n",
    "spectra1_matched = spectra1[matches_within_tolerance]\n",
    "sp_tab1_matched = sp_tab1[matches_within_tolerance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff2337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, Column, unique, vstack\n",
    "\n",
    "apogee_tab1_selected = apogee_tab1_matched['APOGEE_ID', 'RA', 'DEC', 'FE_H', 'FE_H_ERR']\n",
    "\n",
    "apogee_tab2_selected = apogee_tab2['APOGEE_ID', 'RA', 'DEC', 'FE_H', 'FE_H_ERR']\n",
    "\n",
    "# Vertically stack the tables with the selected columns\n",
    "apogee_tab_combined = vstack([apogee_tab1_selected, apogee_tab2_selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48fb51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = set(spectra1_matched.colnames).intersection(spectra2.colnames)\n",
    "\n",
    "# Select only the common columns from each table\n",
    "spectra1_common = spectra1_matched[list(common_cols)]\n",
    "spectra2_common = spectra2[list(common_cols)]\n",
    "spectra_combined = vstack([spectra1_common, spectra2_common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59afcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = set(sp_tab1_matched.colnames).intersection(sp_tab2.colnames)\n",
    "\n",
    "# Select only the common columns from each table\n",
    "sp1_common = sp_tab1_matched[list(common_cols)]\n",
    "sp2_common = sp_tab2[list(common_cols)]\n",
    "sp_combined = vstack([sp1_common, sp2_common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b484d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out abnormal rows for [Fe/H]\n",
    "abnormal_rows = np.where((np.isnan(apogee_tab_combined['FE_H'])) | (apogee_tab_combined['FE_H'] > 10)\n",
    "                        |(apogee_tab_combined['FE_H'] == 0) |\n",
    "                        (apogee_tab_combined['FE_H_ERR'] == 0) |\n",
    "                        (np.isnan(apogee_tab_combined['FE_H_ERR'])))[0]\n",
    "\n",
    "# Create a mask to filter out the abnormal rows\n",
    "mask = ~np.isin(np.arange(len(apogee_tab_combined)), abnormal_rows)\n",
    "\n",
    "# Apply the mask to the datasets to filter out the abnormal rows\n",
    "apogee_tab_masked = apogee_tab_combined[mask]\n",
    "spectra_masked = spectra_combined[mask]\n",
    "sp_masked = sp_combined[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcbfb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectra normalization\n",
    "gb_combined_spectra = Table(names=['combined_flux', 'combined_wavelength'], dtype=['object', 'object'])\n",
    "\n",
    "for row in spectra_masked:\n",
    "    # Combine and sort flux and wavelength from all arms\n",
    "    combined_flux = np.concatenate([row['flx_B'], row['flx_R'], row['flx_Z']])\n",
    "    combined_wavelength = np.concatenate([row['B_WAVELENGTH'], row['R_WAVELENGTH'], row['Z_WAVELENGTH']])\n",
    "    sort_order = np.argsort(combined_wavelength)\n",
    "    combined_flux, combined_wavelength = combined_flux[sort_order], combined_wavelength[sort_order]\n",
    "\n",
    "    # Normalize flux\n",
    "    global_median = np.median(combined_flux)\n",
    "    IQR = np.percentile(combined_flux, 75) - np.percentile(combined_flux, 25)\n",
    "    normalized_flux = (combined_flux - global_median) / IQR\n",
    "\n",
    "    gb_combined_spectra.add_row([normalized_flux, combined_wavelength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eacddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux = np.array(gb_combined_spectra['combined_flux'])\n",
    "# Input spectra\n",
    "X = np.array([np.array(flux_val, dtype=float) for flux_val in flux])\n",
    "# Parameters\n",
    "theta = np.array(apogee_tab_masked[\"FE_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1e105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, theta, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, X_test = map(torch.Tensor, (X_train, X_test))\n",
    "y_train, y_test = map(torch.Tensor, (y_train, y_test))\n",
    "y_train, y_test = y_train.unsqueeze(-1), y_test.unsqueeze(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c55c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_grid = np.arange(-3, 1.01, 0.01)\n",
    "Z_grid = torch.tensor(z_grid, dtype = torch.float32).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c0a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tingli/anaconda3/envs/abunnn/lib/python3.10/site-packages/sbi/neural_nets/flow.py:142: UserWarning: In one-dimensional output space, this flow is limited to Gaussians\n",
      "  warn(\"In one-dimensional output space, this flow is limited to Gaussians\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 104 epochs."
     ]
    }
   ],
   "source": [
    "inference = SNPE(density_estimator=\"maf\")\n",
    "inference.append_simulations(y_train, X_train)\n",
    "density_estimator = inference.train()\n",
    "posterior = inference.build_posterior(density_estimator)\n",
    "\n",
    "# save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1464342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_calib = np.array([np.exp(posterior.log_prob(Z_grid, X_train[i])) for i in range(len(X_train))]) # pdf from sbi for training\n",
    "# np.save\n",
    "cde_test = np.array([np.exp(posterior.log_prob(Z_grid, X_test[i])) for i in range(len(X_test))]) # pdf from sbi for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e74fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.trapz(cde_calib, z_grid) # or Z?\n",
    "norm[norm==0] = 1\n",
    "cde_calib = cde_calib/norm[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8c616b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.trapz(cde_test, z_grid)\n",
    "norm[norm==0] = 1\n",
    "cde_test = cde_test/norm[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427abf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.65442007e-03, 9.65019393e-03, 1.07477908e-02, ...,\n",
       "        1.46945982e-24, 1.02318291e-24, 7.11590699e-25],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.47157633e-41, 7.34560553e-42, 1.53442160e-42],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.22338879e-12, 5.46613566e-12, 3.22288966e-12],\n",
       "       [1.68473970e-29, 3.48275120e-29, 7.17126519e-29, ...,\n",
       "        2.14694394e-39, 9.22571707e-40, 3.94881805e-40],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.08361604e-31, 1.49366541e-31, 2.70551339e-32]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cde_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c76d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = calpit.nn.models.MLP(input_dim = 1+13787, hidden_layers = [4000, 2000, 1000, 500, 100, 50],\n",
    "                                output_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c64a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "| layers.0.weight  |  55152000  |\n",
      "|  layers.0.bias   |    4000    |\n",
      "| layers.1.weight  |     1      |\n",
      "| layers.2.weight  |  8000000   |\n",
      "|  layers.2.bias   |    2000    |\n",
      "| layers.3.weight  |     1      |\n",
      "| layers.4.weight  |  2000000   |\n",
      "|  layers.4.bias   |    1000    |\n",
      "| layers.5.weight  |     1      |\n",
      "| layers.6.weight  |   500000   |\n",
      "|  layers.6.bias   |    500     |\n",
      "| layers.7.weight  |     1      |\n",
      "| layers.8.weight  |   50000    |\n",
      "|  layers.8.bias   |    100     |\n",
      "| layers.9.weight  |     1      |\n",
      "| layers.10.weight |    5000    |\n",
      "|  layers.10.bias  |     50     |\n",
      "| layers.11.weight |     1      |\n",
      "| layers.12.weight |     50     |\n",
      "|  layers.12.bias  |     1      |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 65714707\n"
     ]
    }
   ],
   "source": [
    "calpit_model = calpit.CalPit(model=nn_model)\n",
    "# lot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b04911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1/1000] | train_loss: 0.71936 |valid_bce: 0.69420 | \n",
      "Validation loss decreased (inf --> 0.694198).  Saving model ...\n",
      "[   2/1000] | train_loss: 0.68918 |valid_bce: 0.68659 | \n",
      "Validation loss decreased (0.694198 --> 0.686587).  Saving model ...\n",
      "[   3/1000] | train_loss: 0.68672 |valid_bce: 0.68901 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[   4/1000] | train_loss: 0.68534 |valid_bce: 0.68550 | \n",
      "Validation loss decreased (0.686587 --> 0.685500).  Saving model ...\n",
      "[   5/1000] | train_loss: 0.68376 |valid_bce: 0.67829 | \n",
      "Validation loss decreased (0.685500 --> 0.678294).  Saving model ...\n",
      "[   6/1000] | train_loss: 0.68055 |valid_bce: 0.67799 | \n",
      "Validation loss decreased (0.678294 --> 0.677986).  Saving model ...\n",
      "[   7/1000] | train_loss: 0.68072 |valid_bce: 0.67800 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[   8/1000] | train_loss: 0.67731 |valid_bce: 0.68824 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[   9/1000] | train_loss: 0.67873 |valid_bce: 0.67753 | \n",
      "Validation loss decreased (0.677986 --> 0.677526).  Saving model ...\n",
      "[  10/1000] | train_loss: 0.67307 |valid_bce: 0.67939 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  11/1000] | train_loss: 0.67416 |valid_bce: 0.67322 | \n",
      "Validation loss decreased (0.677526 --> 0.673225).  Saving model ...\n",
      "[  12/1000] | train_loss: 0.67459 |valid_bce: 0.67167 | \n",
      "Validation loss decreased (0.673225 --> 0.671668).  Saving model ...\n",
      "[  13/1000] | train_loss: 0.67082 |valid_bce: 0.67137 | \n",
      "Validation loss decreased (0.671668 --> 0.671370).  Saving model ...\n",
      "[  14/1000] | train_loss: 0.67048 |valid_bce: 0.67027 | \n",
      "Validation loss decreased (0.671370 --> 0.670273).  Saving model ...\n",
      "[  15/1000] | train_loss: 0.66865 |valid_bce: 0.67324 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  16/1000] | train_loss: 0.66552 |valid_bce: 0.66708 | \n",
      "Validation loss decreased (0.670273 --> 0.667079).  Saving model ...\n",
      "[  17/1000] | train_loss: 0.66793 |valid_bce: 0.67178 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  18/1000] | train_loss: 0.66597 |valid_bce: 0.66448 | \n",
      "Validation loss decreased (0.667079 --> 0.664479).  Saving model ...\n",
      "[  19/1000] | train_loss: 0.66808 |valid_bce: 0.66826 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  20/1000] | train_loss: 0.66609 |valid_bce: 0.66461 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  21/1000] | train_loss: 0.66268 |valid_bce: 0.66255 | \n",
      "Validation loss decreased (0.664479 --> 0.662548).  Saving model ...\n",
      "[  22/1000] | train_loss: 0.66272 |valid_bce: 0.66322 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  23/1000] | train_loss: 0.66429 |valid_bce: 0.66154 | \n",
      "Validation loss decreased (0.662548 --> 0.661540).  Saving model ...\n",
      "[  24/1000] | train_loss: 0.66316 |valid_bce: 0.65949 | \n",
      "Validation loss decreased (0.661540 --> 0.659489).  Saving model ...\n",
      "[  25/1000] | train_loss: 0.66083 |valid_bce: 0.65905 | \n",
      "Validation loss decreased (0.659489 --> 0.659047).  Saving model ...\n",
      "[  26/1000] | train_loss: 0.65767 |valid_bce: 0.65793 | \n",
      "Validation loss decreased (0.659047 --> 0.657927).  Saving model ...\n",
      "[  27/1000] | train_loss: 0.65724 |valid_bce: 0.66703 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  28/1000] | train_loss: 0.66226 |valid_bce: 0.66265 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  29/1000] | train_loss: 0.65725 |valid_bce: 0.65528 | \n",
      "Validation loss decreased (0.657927 --> 0.655281).  Saving model ...\n",
      "[  30/1000] | train_loss: 0.65801 |valid_bce: 0.65581 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  31/1000] | train_loss: 0.65902 |valid_bce: 0.65560 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  32/1000] | train_loss: 0.65622 |valid_bce: 0.65393 | \n",
      "Validation loss decreased (0.655281 --> 0.653930).  Saving model ...\n",
      "[  33/1000] | train_loss: 0.65826 |valid_bce: 0.66531 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  34/1000] | train_loss: 0.65516 |valid_bce: 0.65232 | \n",
      "Validation loss decreased (0.653930 --> 0.652322).  Saving model ...\n",
      "[  35/1000] | train_loss: 0.65279 |valid_bce: 0.65284 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  36/1000] | train_loss: 0.64879 |valid_bce: 0.65126 | \n",
      "Validation loss decreased (0.652322 --> 0.651260).  Saving model ...\n",
      "[  37/1000] | train_loss: 0.65024 |valid_bce: 0.65327 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  38/1000] | train_loss: 0.64717 |valid_bce: 0.65013 | \n",
      "Validation loss decreased (0.651260 --> 0.650132).  Saving model ...\n",
      "[  39/1000] | train_loss: 0.64800 |valid_bce: 0.64628 | \n",
      "Validation loss decreased (0.650132 --> 0.646284).  Saving model ...\n",
      "[  40/1000] | train_loss: 0.64849 |valid_bce: 0.65173 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  41/1000] | train_loss: 0.64804 |valid_bce: 0.64431 | \n",
      "Validation loss decreased (0.646284 --> 0.644311).  Saving model ...\n",
      "[  42/1000] | train_loss: 0.64751 |valid_bce: 0.64519 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  43/1000] | train_loss: 0.64472 |valid_bce: 0.65052 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  44/1000] | train_loss: 0.64614 |valid_bce: 0.64195 | \n",
      "Validation loss decreased (0.644311 --> 0.641955).  Saving model ...\n",
      "[  45/1000] | train_loss: 0.64425 |valid_bce: 0.64377 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  46/1000] | train_loss: 0.64086 |valid_bce: 0.64839 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  47/1000] | train_loss: 0.64278 |valid_bce: 0.64353 | \n",
      "EarlyStopping counter: 3 out of 20\n",
      "[  48/1000] | train_loss: 0.64277 |valid_bce: 0.64716 | \n",
      "EarlyStopping counter: 4 out of 20\n",
      "[  49/1000] | train_loss: 0.63923 |valid_bce: 0.64000 | \n",
      "Validation loss decreased (0.641955 --> 0.639999).  Saving model ...\n",
      "[  50/1000] | train_loss: 0.63737 |valid_bce: 0.64171 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  51/1000] | train_loss: 0.63645 |valid_bce: 0.63648 | \n",
      "Validation loss decreased (0.639999 --> 0.636479).  Saving model ...\n",
      "[  52/1000] | train_loss: 0.63707 |valid_bce: 0.63975 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  53/1000] | train_loss: 0.63618 |valid_bce: 0.63455 | \n",
      "Validation loss decreased (0.636479 --> 0.634554).  Saving model ...\n",
      "[  54/1000] | train_loss: 0.63602 |valid_bce: 0.63745 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  55/1000] | train_loss: 0.63011 |valid_bce: 0.64130 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  56/1000] | train_loss: 0.63423 |valid_bce: 0.63570 | \n",
      "EarlyStopping counter: 3 out of 20\n",
      "[  57/1000] | train_loss: 0.63234 |valid_bce: 0.63186 | \n",
      "Validation loss decreased (0.634554 --> 0.631859).  Saving model ...\n",
      "[  58/1000] | train_loss: 0.63452 |valid_bce: 0.63899 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  59/1000] | train_loss: 0.63425 |valid_bce: 0.63033 | \n",
      "Validation loss decreased (0.631859 --> 0.630331).  Saving model ...\n",
      "[  60/1000] | train_loss: 0.63109 |valid_bce: 0.63047 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  61/1000] | train_loss: 0.62581 |valid_bce: 0.62780 | \n",
      "Validation loss decreased (0.630331 --> 0.627801).  Saving model ...\n",
      "[  62/1000] | train_loss: 0.62817 |valid_bce: 0.62699 | \n",
      "Validation loss decreased (0.627801 --> 0.626995).  Saving model ...\n",
      "[  63/1000] | train_loss: 0.62268 |valid_bce: 0.62737 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  64/1000] | train_loss: 0.62785 |valid_bce: 0.63499 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  65/1000] | train_loss: 0.62490 |valid_bce: 0.62670 | \n",
      "Validation loss decreased (0.626995 --> 0.626699).  Saving model ...\n",
      "[  66/1000] | train_loss: 0.62196 |valid_bce: 0.62425 | \n",
      "Validation loss decreased (0.626699 --> 0.624248).  Saving model ...\n",
      "[  67/1000] | train_loss: 0.61957 |valid_bce: 0.62126 | \n",
      "Validation loss decreased (0.624248 --> 0.621259).  Saving model ...\n",
      "[  68/1000] | train_loss: 0.62594 |valid_bce: 0.62171 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  69/1000] | train_loss: 0.62309 |valid_bce: 0.62543 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  70/1000] | train_loss: 0.61974 |valid_bce: 0.62667 | \n",
      "EarlyStopping counter: 3 out of 20\n",
      "[  71/1000] | train_loss: 0.61663 |valid_bce: 0.62098 | \n",
      "Validation loss decreased (0.621259 --> 0.620982).  Saving model ...\n",
      "[  72/1000] | train_loss: 0.61664 |valid_bce: 0.61508 | \n",
      "Validation loss decreased (0.620982 --> 0.615081).  Saving model ...\n",
      "[  73/1000] | train_loss: 0.61590 |valid_bce: 0.61729 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  74/1000] | train_loss: 0.61405 |valid_bce: 0.61268 | \n",
      "Validation loss decreased (0.615081 --> 0.612682).  Saving model ...\n",
      "[  75/1000] | train_loss: 0.61415 |valid_bce: 0.61055 | \n",
      "Validation loss decreased (0.612682 --> 0.610551).  Saving model ...\n",
      "[  76/1000] | train_loss: 0.60928 |valid_bce: 0.60776 | \n",
      "Validation loss decreased (0.610551 --> 0.607765).  Saving model ...\n",
      "[  77/1000] | train_loss: 0.60775 |valid_bce: 0.60721 | \n",
      "Validation loss decreased (0.607765 --> 0.607205).  Saving model ...\n",
      "[  78/1000] | train_loss: 0.60729 |valid_bce: 0.60619 | \n",
      "Validation loss decreased (0.607205 --> 0.606187).  Saving model ...\n",
      "[  79/1000] | train_loss: 0.60693 |valid_bce: 0.60352 | \n",
      "Validation loss decreased (0.606187 --> 0.603516).  Saving model ...\n",
      "[  80/1000] | train_loss: 0.61148 |valid_bce: 0.60632 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  81/1000] | train_loss: 0.60374 |valid_bce: 0.60805 | \n",
      "EarlyStopping counter: 2 out of 20\n",
      "[  82/1000] | train_loss: 0.60430 |valid_bce: 0.60427 | \n",
      "EarlyStopping counter: 3 out of 20\n",
      "[  83/1000] | train_loss: 0.60141 |valid_bce: 0.59936 | \n",
      "Validation loss decreased (0.603516 --> 0.599363).  Saving model ...\n",
      "[  84/1000] | train_loss: 0.60298 |valid_bce: 0.61143 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  85/1000] | train_loss: 0.60023 |valid_bce: 0.59875 | \n",
      "Validation loss decreased (0.599363 --> 0.598754).  Saving model ...\n",
      "[  86/1000] | train_loss: 0.59855 |valid_bce: 0.60356 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  87/1000] | train_loss: 0.59914 |valid_bce: 0.59794 | \n",
      "Validation loss decreased (0.598754 --> 0.597942).  Saving model ...\n",
      "[  88/1000] | train_loss: 0.59795 |valid_bce: 0.59761 | \n",
      "Validation loss decreased (0.597942 --> 0.597610).  Saving model ...\n",
      "[  89/1000] | train_loss: 0.59196 |valid_bce: 0.59390 | \n",
      "Validation loss decreased (0.597610 --> 0.593897).  Saving model ...\n",
      "[  90/1000] | train_loss: 0.59538 |valid_bce: 0.59426 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  91/1000] | train_loss: 0.59603 |valid_bce: 0.59274 | \n",
      "Validation loss decreased (0.593897 --> 0.592737).  Saving model ...\n",
      "[  92/1000] | train_loss: 0.59403 |valid_bce: 0.60019 | \n",
      "EarlyStopping counter: 1 out of 20\n",
      "[  93/1000] | train_loss: 0.59530 |valid_bce: 0.59266 | \n",
      "Validation loss decreased (0.592737 --> 0.592664).  Saving model ...\n",
      "[  94/1000] | train_loss: 0.58641 |valid_bce: 0.59165 | \n",
      "Validation loss decreased (0.592664 --> 0.591647).  Saving model ...\n",
      "[  95/1000] | train_loss: 0.59113 |valid_bce: 0.59096 | \n",
      "Validation loss decreased (0.591647 --> 0.590957).  Saving model ...\n",
      "[  96/1000] | train_loss: 0.58886 |valid_bce: 0.58975 | \n",
      "Validation loss decreased (0.590957 --> 0.589749).  Saving model ...\n",
      "[  97/1000] | train_loss: 0.59003 |valid_bce: 0.58856 | \n",
      "Validation loss decreased (0.589749 --> 0.588559).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "trained_model = calpit_model.fit(X_train, # input features\n",
    "                                 y_train, # True labels -> y_train\n",
    "                                 cde_calib, # Initial CDEs/pdfs\n",
    "                                 z_grid, # Grid on which CDEs/pdfs are evaluated\n",
    "                                 n_epochs=1000, #number of epochs to train\n",
    "                                 patience = 20,\n",
    "                                 batch_size = 128,\n",
    "                                 lr = 1e-6,\n",
    "                                 ) # See documentation for additional training hyperparameters\n",
    "# Plot train_loss - should decrease over time - if not y_train check\n",
    "# Use all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4275c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cov_grid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m201\u001b[39m) \u001b[38;5;66;03m# The grid of (mis)-coverage values on which to evaluate the conditional PIT distribution\u001b[39;00m\n\u001b[1;32m      3\u001b[0m pit_conditional_test \u001b[38;5;241m=\u001b[39m calpit_model\u001b[38;5;241m.\u001b[39mpredict(x_test \u001b[38;5;241m=\u001b[39m X_test, cov_grid\u001b[38;5;241m=\u001b[39mcov_grid) \u001b[38;5;66;03m#Predict the local PIT distribution for a test dataset\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "cov_grid = np.linspace(0,1,201) # The grid of (mis)-coverage values on which to evaluate the conditional PIT distribution\n",
    "\n",
    "pit_conditional_test = calpit_model.predict(x_test = X_test, cov_grid=cov_grid) #Predict the local PIT distribution for a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ffeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_conditional_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random sample of 12 P-P plots\n",
    "SEED = 299792458\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "random_idx = rng.choice(len(X_test[:100]), 12, replace=False)\n",
    "\n",
    "fig, axs = plt.subplots(3,4, figsize=(13, 8))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for count, index in enumerate(random_idx):\n",
    "    axs[count].scatter(cov_grid, pit_conditional_test[index], s=1)\n",
    "    axs[count].plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10), color=\"k\", ls=\"--\")\n",
    "    axs[count].set_xlim(0, 1)\n",
    "    axs[count].set_ylim(0, 1)\n",
    "    axs[count].set_aspect(\"equal\")\n",
    "\n",
    "fig.suptitle(\"Local PIT Distribution\", fontsize=20)\n",
    "\n",
    "fig.text(0.35,0.01,\"Expected Cumulative Probability\",fontsize=20)\n",
    "fig.text(0.,0.2,\"Empirical Cumulative Probability\", rotation=90, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62087f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "recal_cde_test = calpit_model.transform(x_test = X_test[:100], cde_test=cde_test, y_grid = z_grid) #Get the recalibrated CDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8444c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cde =calpit.utils.normalize(recal_cde_test,z_grid) # Normalize the CDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bd750",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bda83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing the before and after CDEs\n",
    "fig, axs = plt.subplots(3,4, figsize=(14,8))\n",
    "\n",
    "\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for count, index in enumerate(random_idx):\n",
    "\n",
    "    axs[count].plot(z_grid, cde_test[index], c=\"C0\")\n",
    "    axs[count].plot(z_grid, recal_cde_test[index], c=\"C1\")\n",
    "    axs[count].axvline(y_test[index], 0, 1, c=\"k\", ls=\"--\", lw=1)\n",
    "    axs[count].set_xlabel(r\"$z$\")\n",
    "    axs[count].set_ylabel(r\"$\\hat{f}(z)$\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "blue_line = mlines.Line2D([], [], color='C0', marker=\"\", alpha=1, label='Original', ls=\"-\")\n",
    "orange_line = mlines.Line2D([], [], color='C1', marker='', alpha=1, label='Recalibrated', ls=\"-\")\n",
    "black_line = mlines.Line2D([], [], color='k', marker='', alpha=1, label='True\\n redshift', ls=\"--\")\n",
    "\n",
    "fig.legend(bbox_to_anchor=[0.13,0.3], loc='upper left', handles=[blue_line,orange_line,black_line ], ncol=1, prop={'size': 12}, frameon=False, handlelength=1.0, handletextpad=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e14e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abunnn",
   "language": "python",
   "name": "abunnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
